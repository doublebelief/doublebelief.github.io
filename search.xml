<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[自动化机器学习综述笔记]]></title>
    <url>%2F2019%2F08%2F06%2FAutoMLSurveyNotes%2F</url>
    <content type="text"><![CDATA[Auto Machine Learning Survey Notes(Ⅰ) Paper Name: Yao, Q., Wang, M., Chen, Y., Dai, W., Yi-Qi, H., Yu-Feng, L., … Yang, Y. (2018). Taking Human out of Learning Applications: A Survey on Automated Machine Learning. 1–26. Retrieved from http://arxiv.org/abs/1810.13306 First Section In first section,this paper first explains why we need to investigate AutoML. Its reason is following. Machine Learning has been popular recently , but every aspect of machine learning applications, such as feature engineering, model selection, and algorithm selection, needs to be carefully configured, which costs the efforts of many human experts. So we need to research AutoML to take human out of Learning Application and give experts more time to analyze data and problem,and finally promote the development of Machine Learning. This paper also gives some examples of automated machine learning in industry and academic, like Auto-sklearn, Google’s cloud autoML , and Feature Labs, which shows that AutoML has already been successfully applied in many important problems. 在第一部分中，本文首先解释了为什么我们需要研究AutoML。 因为机器学习近些年很流行，但机器学习应用的各个方面，如特征工程，模型选择和算法选择，都需要仔细配置，这需要许多专业人士的努力。所以我们需要研究AutoML以使人类能够从模型训练中解放出来，能够集中精力分析数据和问题本身，最终促进机器学习的发展。 本文还提供了一些工业和学术界自动化机器学习的例子，如Auto-sklearn，Google的 Cloud AutoML，还有Feature Labs，它们表明了AutoML已成功应用于许多重要问题。 Second SectionIn second section, this paper firstly defines AutoML and its core goal. AutoML attempts to construct machine learning programs(specified by Experience, Task and Performance ),without human assitance and within limited computational budgets. And its three core goals are good performance , no assistance from humans and high computational efficiency. Next, this paper propose a basic framework for AutoML approaches. In this framework, an AutoML controller, which has two key ingredients,the optimizer and the evaluator, takes the place of human to find proper configurations for the learning tools. The duty of the evaluator is to measure the performance of the learning tools with configurations provided by the optimizer , while the optimizer’s duty is to update or generate configurations for learning tools. Finally, this paper shows AutoML approaches taxonomies by problem setup and techniques. 在第二部分中，本文首先定义了AutoML及其核心目标。 AutoML尝试构建机器学习程序（由经验，任务和性能指定），无需人工协助并且在有限的计算预算内。 它的三个核心目标是良好的性能，没有人类的帮助和高计算效率。 接下来，本文提出了AutoML方法的基本框架。 在这个框架中，AutoML控制器取代了人类的工作，为学习方法找到合适的配置方式，这个控制器有两个关键组成部分，即优化器和评估器。 在本节的最后，本文将AutoML的方法分为问题设置和技术处理两类。 Third SectionIn third section, this paper gives details on problem setup and introduces some existing AutoML approaches on learning process. AutoML approaches do not necessarily cover the full machine learning pipeline, they can also focus on some parts of the learning process. As for some parts of the learning process, AutoML approaches includes feature engineering , model selection, and optimization algorithm selection. Feature engineering is to automatically construct features from the data so that subsequent learning tools can have good performance. This goal can be divided into two sub-problems. creating features from the data and enhance features’ discriminative ability. However, there are no common or principled methods to create features from data. So , now AutoML focus on feature enhancing methods and there are some common methods to enhance features, dimension reduction,feature generation and feature encoding. Models selection contains two components, picking up some classifiers and setting their corresponding hyper-parameters. The task of model selection is to automatically select classifiers and set their hyper-parameters so that good learning performance can be contained. The goal of optimization algorithm selection is to automatically find an optimization algorithm so that efficiency and performance can be balanced. What’s more, in this section, this paper give two classes of full-scope AutoML approaches. The first one is general case, which is a combination of feature engineering, model selection and algorithm selection. The second one is Network Architecture Search (NAS), which targets at searching good deep network architectures that suit the learning problem. 在第三部分中，本文详细介绍了问题的设置，并介绍了一些现有的AutoML的方法。AutoML可以不必覆盖机器学习的全范围，仅专注于学习过程中的一部分。 针对机器学习的某些部分，AutoML的方法可分为特征工程，模型选择和优化算法选择。特征工程是从数据中自动构造特征，以便后续学习工具可以具有良好的性能。这个目标可以分为两个子问题，一个是从数据创建功能，另一个是增强功能的辨别能力。但是，没有通用或原则方法从数据创建功能。因此，现在AutoML专注于特征增强方法，并且有一些常用方法可以增强特征，例如降维，特征生成和特征编码。模型选择包含两个组成部分，分别是选取分类器和设置其相应的超参数。模型选择的任务是自动选择分类器并设置其超参数，以便可以包含良好的学习性能。优化算法选择的目标是自动找到优化算法，以便平衡效率和性能。 此外，在本节中，本文提供了两类全范围AutoML方法。第一个是一般情况，它是特征工程，模型选择和算法选择的组合。第二个是网络架构搜索（NAS），其目标是搜索适合学习问题的良好深度网络架构。 Fourth SectionIn fourth section, this paper introduces some basic techniques for optimizer. It has three parts including simple search approaches, optimization from samples and gradient descent. Simple search is a naive search approach, and grid search and random search are two common approaches. Optimization from samples is a kind of smarter search approach, and this paper divide existing approaches into three categories, heuristic search, model-based derivative-free optimization, and reinforcement learning. Some popular heuristic search methods are Particle swarm optimization(PSO), Evolutionary Algorithms. The popular methods of model-based derivative-free optimization are Bayesian optimization, classification-based optimization (CBO) and simultaneous optimistic optimization (SOO) . Reinforcement learning (RL) is a very general and strong optimization framework, which can solve problems with delayed feedbacks. Greedy search is a natural strategy to solve multi-step decision-making problem. 在第四部分中，本文介绍了优化器的一些基本技术。 它有三个部分，包括简单搜索方法，样本优化和梯度下降。 简单搜索是一种朴素的搜索方法，其中两种常见的方法分别是网格搜索和随机搜索。样本优化是一种更智能的搜索方法，本文将现有的相关方法分为三类：启发式搜索，基于模型的无导数优化和强化学习。 一些流行的启发式搜索方法是粒子群优化（PSO），进化算法。 基于模型的无导数优化的流行方法是贝叶斯优化，基于分类的优化（CBO）和同时优化优化（SOO）。 强化学习（RL）是一个非常通用且强大的优化框架，可以解决延迟反馈的问题。此外，贪心搜索是解决多步决策问题的常用策略。 Fifth SectionIn fifth section, this paper introduce some basic techniques for evaluator. And the existing methods are direct evaluation, sub-sampling, early stop, parameter reusing and surrogate evaluator. Direct evaluation is often accurate but expensive, and some other methods have been proposed for acceleration by trading evaluation accuracy for efficiency. 在第五部分，本文介绍了评估器的一些基本技术。 现有的方法有直接评估，子抽样，早期停止，参数重用和代理评估。 直接评估通常是准确的但效率不高，而其他的方法是来通过降低评估准确性来提高效率。 Sixth SectionIn sixth section, this paper introduce some experienced techniques , there are two main topics, meta-learning and transfer learning. Meta-learning helps AutoML, on the one hand, by characterizing learning problems and tools.,on the other hand, the meta-learner encodes past experience and acts as a guidance to solve future problems. Existing meta-learning techniques by categorizing them into three general classes based on their applications in AutoML are following: meta-learning for configuration evaluation (for the evaluator). Meta-learners can be trained as surrogate evaluators to predict performances, applicabilities, or ranking of configurations. Representative applications of meta-learning in configuration evaluation are Model evaluation and General configuration evaluation. meta- learning for configuration generation (for the optimizer). The approaches have promising configuration generation, warming-starting configuration generation , and search space refining. meta-learning for dynamic configuration adaptation. Meta-learning can help to automate this procedure by detecting concept drift and dynamically adapting learningdrift. Transfer learning tries to improve the learning on target domain and learning task, by using the knowledge from the source domain and learning task. Transfer learning has been exploited to reuse trained surrogate models or promising search strategies from past AutoML search (source) and improve the efficiency in current AutoML task (target). By transferring knowledge from previous configuration evaluations, we can avoid training model from scratch for the upcoming evaluations and significantly improve the efficiency. 在第六部分，本文介绍了一些比较先进的技术，主要有两个主题，元学习和迁移学习。 元学习辅助AutoML，一方面通过对学习问题和工具的表征。另一方面，通过编码以往的经验来作为对解决未来问题的指导。 基于AutoML中的应用程序，将现有的元学习技术分为三个通用类： 1.用于配置评估的元学习（用于评估器）。元学习器可以作为代理评估器进行训练，以预测性能，适用性或配置排名。元学习在配置评估中的代表性应用有模型评估和一般配置评估这两种。2.用于配置生成的元学习（用于优化器）。相关方法有：良好配置生成，预热配置生成和搜索空间精炼。3.动态配置适应的元学习。元学习可以通过检测概念转换和动态调整学习转换来帮助AutoML。 迁移学习通过使用来自源域和学习任务的知识，尝试改进对目标域和学习任务的学习。 迁移学习能重用过去AutoML任务（源）经过训练的代理模型或优良的搜索策略，并提高当前AutoML任务（目标）的效率。通过从以前的配置评估中迁移知识，可以避免从头训练模型，显著提高效率。 Seventh SectionIn seventh section, this paper introduce three AutoML examples, Auto-sklearn, NASNet and ExploreKit. In Auto-sklearn, model selection is formulated as a CASH problem, which aims to minimize the validation loss with respect to the model as well as its hyper-parameters and parameters. RL is employed in NAS to search for a optimal sequence of design decisions. Besides, the direct evaluation is used in these works as the evaluator. As RL is slow to converge, to make the search faster, transfer learning, which is firstly used to cut the search space into several blocks. ExploreKit conducts more expensive and accurate evaluations on the candidate features. Error reduction on the validation set is used as the metric for feature importance. Candidate features are evaluated successively according to their ranking, and selected if their usefulness surpass a threshold. This procedure terminates if enough improvement is achieved. The selected features will be used to generate new candidates in the following iterations. 在第七部分中，本文介绍了三个AutoML应用示例，Auto-sklearn，NASNet和ExploreKit。 在Auto-sklearn中，模型选择被公式化为CASH问题，其目的是最小化模型的验证损失函数及其超参数和参数。 NAS使用RL来搜索最佳的设计决策序列，使用直接评估作为整个工作的评估器。但RL收敛缓慢，为了使搜索更快，NAS使用了转移学习，在搜索之前将搜索空间切割成几个块，以加快收敛速度。 ExploreKit对候选功能进行更准确但更低效的评估。将验证集上的错误减少情况用作特征有效性的度量标准，按照相应排名对候选特征进行评估，并选择有效性超过阈值的特征，所选的特征将在以下的迭代中生成新候选。如果实现了足够的效果，则迭代过程终止。 Eighth SectionIn eighth section, this paper reviews the history of AutoML, summarizes how its current status in the academy and industry, and discuss its future work. AutoML only becomes practical and a big focus recently, due to the big data, the increasing computation of modern computers, and of course, the great demand of machine learning application. AutoML is a very complex problem and also an extremely active research area, and there are many new opportunities and problems in AutoML. And there are also many workshops and competitions. Higher efficiency can be achieved by either proposing algorithms for the optimizer, which visit less configurations before reaching a good performance, or designing better methods for the evaluator, which can offer more accurate evaluations but in less time. 在第八部分，本文回顾了AutoML的历史，总结了其在学术界和行业中的现状，并讨论了其未来的发展方向。 由于大数据，现代计算机的计算量不断增加，当然还有机器学习应用的巨大需求，AutoML最近才成为重点。 AutoML是一个非常复杂的问题，也是一个非常活跃的研究领域，AutoML中存在许多新的机会和问题，还有许多研讨会和比赛。 为优化器提出算法可以实现更高的效率，这样使得优化器在达到良好性能之前访问较少的配置；或者为评估器设计更好的方法，这可以在更短的时间内提供更准确的评估。]]></content>
      <categories>
        <category>Book Notes</category>
      </categories>
      <tags>
        <tag>AutoML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习读书笔记（Ⅰ）]]></title>
    <url>%2F2019%2F07%2F24%2FMachineLearningBookNotes%2F</url>
    <content type="text"><![CDATA[Notes on Machine Learning重要名词解释Important Expressions训练集train set： 用于模型训练的数据集 验证集validation set：用于进行模型评估和模型选择的数据集 测试集test set：用来评估模型在实际使用中的泛化能力 形象上来说训练集就像是学生的课本，学生 根据课本里的内容来掌握知识，验证集就像是作业，通过作业可以知道 不同学生学习情况、进步的速度快慢，而最终的测试集就像是考试，考的题是平常都没有见过，考察学生举一反三的能力。 错误率error rate:分类错误的样本数占样本总数的比例 精度accuracy：分类正确的样本数占样本总数的比例 线性模型Linear Model线性判别分析Linear Discriminant Analysis,LDA:用于解决二分类问题的经典线性学习方法。主要思想：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离。 多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。 最经典的拆分策略有三种：“一对一”（One vs One, OvO)，“一对其余”（One vs Rest，OvR) 和 “多对多”（Many vs Many，MvM） 类别不平衡问题class-imbalance:指分类任务中不同类别的训练样例数目差别很大的情况。三类处理方案，第一类是欠采样（under sampling)即去除训练集中数目较多类别的样例；第二类是过采样（over sampling)即增加训练集中数目较少类别的样例；第三类是直接基于原始训练集进行训练，但在使用分类器进行预测时修改决策过程，进行“阈值移动”（threshold moving)。 决策树Decision Tree决策树的划分目标：决策树的分支节点所包含的样本尽可能属于同一类别，即结点的“纯度”（purity）越来越高。 神经网络Neural Networks多层前馈神经网络（multi-layer feedforward neural networks)：每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络称之为多层前馈神经网络。 神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”（connection weight）以及每个功能神经元的阈值；换言之。神经网络学到的东西，蕴含在连接权与阈值中。 常见的神经网络： RBF(Radial Basis Function，径向基函数)网络，这是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。 ART（Adaptive Resonance Theory， 自适应谐振理论）网络，它采用竞争型学习（一种常用的无监督学习策略）的策略，由比较层、识别层、识别阈值和重置模块构成。 SOM（Self-Organizing Map，自组织映射）网络，这是一种竞争学习型的无监督神经网络，它能将高位输入数据映射到低维空间（通常是二维）,同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元。 级联相关网络（cascade-correlation) 是结构自适应的神经网络。 Elman网络是递归神经网络。与前馈神经网络不同，递归神经网络（recurrent neural networks)允许网络中出现环形结构，从而可以让一些神经元的输出反馈回来作为输入信号。 Boltzmann机：这是一种“基于能量的模型”（energy-based model)。神经网络中有一类模型是为网络状态定义一个“能量”（energy），能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数。 深度学习deep learning：典型的深度学习模型就是很深层的神经网络。对于神经网络模型，提高容量的一个简单办法就是增加隐层数目，然而多隐层神经网络难以直接使用经典算法（比如标准BP算法）进行训练，因为误差在多隐层内逆传播时，往往会“发散”（diverge）而不能收敛到稳定状态，所以无监督逐层训练（unsupervised layer-wise training)是多隐层网络训练的有效手段，即采用预训练+微调的做法对多隐层网络进行训练，这样可以有效地节省了训练开销。 另一种节省训练开销的策略是”权共享（weight sharing)”，即让一组神经元使用相同的连接权，这个策略在卷积神经网络(Convolutional Neural Network)发挥了重要作用。 贝叶斯分类Bayes Classifier*朴素贝叶斯分类器（naive Bayes classifier) *：朴素贝叶斯分类器采用了属性条件独立假设（attribute conditional independence assumption)，即对已知类别，假设所有属性相互独立，换言之，假设每个属性独立地对分类结果发生影响。之所以使用朴素贝叶斯分类器，是因为贝叶斯分类器难以从有限的训练样本中直接估计所有属性上的联合概率。 EM(Expectation-Maximization)算法：是一种迭代式的方法，用于计算参数隐变量，其基本思想是：若参数Θ已知，则可以根据训练数据推断出最优隐变量Z的值（E步）；反之，若Z的值已知，则可以方便地对参数Θ做最大似然估计（M步）。 集成学习Ensemble Learning*集成学习(ensemble learning) *：通过构建并结合多个学习器来完成学习任务，也被称为多分类器系统（multi-classifier system)。根据个体学习器的生成方式，目前的集成学习方法大致可分为两类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，代表算法是Boosting；另一类是个体学习器之间不存在强依赖关系，可同时生成的并行化方法，代表是Bagging和随机森林（Random Forest)。 Boosting：这是一族可将弱学习器提升为强学习器的算法。这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续收到更多关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最终将这T个基学习器进行加权结合。 Bagging：这是一种并行式集成学习方法，它直接基于自助采样法（Bootstrap sampling)。给定包含m个样本的数据集，先随机取出一个样本放入采样集中，再把样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m次随机采样操作，我们得到m个样本的采样集。其中初始训练集中约有63.2%的样本出现在采样集中。照这样可以采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合，这就是Bagging的基本流程。 随机森林(Random Forest，RF)：RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。具体来说，传统的决策树在选择划分属性时实在当前结点的属性集合（假设有d个属性）中选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最有属性用于划分，这里的参数k控制了随机性的引入程度。 结合策略：平均法，投票法和学习法（通过另一个学习器来结合个体学习器，即通过次级学习器来结合初级学习器）。 聚类Clustering聚类(clustering)：聚类算法是无监督学习（unsupervised learning)，训练样本的标记信息未知，通过聚类，试图将数据集中的样本划分为若干个通常不相交的子集，每个子集称为一个“簇”（cluster)。聚类过程仅能自动形成簇结构，而簇所对应的概念语义需要使用者来进行命名和把握。聚类算法涉及的两个基本问题是性能度量和距离计算。 性能度量(validity index)：性能度量大致有两类： 一类是将聚类结果与某个参考模型（reference model)比较，称为“外部指标”（external index），常用的外部指标有Jaccard系数（Jaccard Coefficient, JC），FM指数（Fowlkes and Mallows Index, FMI)和Rand指数（Rand Index,RI)。这些指数越大说明聚类效果越好。 另一类是直接考察聚类结果而不利用任何参考模型，称为“内部指标”（Internal index)，常用的内部指标有DB指数（Davies-Bouldin Index, DBI）和Dunn指数（Dunn Index,DI)。内部指标中DBI的值越小越好，而DI的值越大越好。 密度聚类（density-based clustering）：通常情形下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果。DBSCAN是一种著名的密度聚类算法。 层次聚类（hierarchical clustering）：这种聚类算法试图在不同层次对数据集进行划分，从而形成树形的聚类结构。AGNES是一种采用自底向上聚合策略的层次聚类算法。 半监督学习Semi-supervised Learning半监督学习（semi-supervised learning)：让学习器不依赖外界交互，自动利用未标记样本来提升学习性能。 半监督支持向量机（semi-supervised support vector machine, S3VM)：这是支持向量机在半监督学习上的推广。 半监督聚类（semi-supervised clustering)：聚类是典型的无监督学习任务，但现实的聚类任务中，我们往往能获取到一些额外的监督信息，这些信息大致有两类，一类是必连（指样本必属于同一个簇）与勿连（指样本必不属于同一个簇）约束，另一类是少量的标记样本。利用这些监督信息，我们可以通过半监督聚类来获得更好的聚类效果。 规则学习Rule Learning规则学习（rule learning)：规则学习是从训练数据中学习出一组能用于对未见示例进行判别的规则。 序贯覆盖（sequential covering)：即逐条归纳，在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程。由于每次只处理一部分数据，因此也被称为“分治”（separate-and-conquer)策略。 一阶规则学习，FOIL算法（First-Order Inductive Learner)：FOIL是著名的一阶规则学习算法，它遵循序贯覆盖框架并且采用自顶向下的规则归纳策略，由于逻辑变量的存在，FOIL在规则生成时需要考虑不同的变量组合。 归纳逻辑程序设计（Inductive Logic Programming，ILP）：归纳逻辑程序设计在一阶规则学习中引入了函数和逻辑表达式嵌套。 强化学习Reinforcement Learning强化学习：强化学习的学习目的就是要找到能使长期累积奖赏最大化的策略。强化学习中没有标记样本，即没有人直接告诉机器在什么状态下应该做什么动作，只有等到最终结果揭晓，才能通过“反思”之前动作是否正确来进行学习，因此，强化学习在某种意义上可看作具有“延迟标记信息”的监督学习问题。 探索与利用(Exploration and Exploitation)：探索（“估计摇臂的优劣”）和利用（“选择当前最优摇臂”）这两者是矛盾的，因为尝试次数有限，加强了一方则会自然削弱另一方，这是强化学习所面临的“探索利用窘境”（Exploration-Exploitation dilemma)。显然，想要强化学习累积奖赏最大，需要在探索和利用之间达到较好的折中。 模仿学习（imitation learning)：在强化学习的经典任务设置中，机器所能获得的反馈信息仅有多步决策后的累计奖赏，但在现实任务中，往往能得到人类专家的决策过程范例，从这样的范例中学习，称为“模仿学习”（imitation learning）。]]></content>
      <categories>
        <category>Book Notes</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习读书笔记（Ⅰ）]]></title>
    <url>%2F2019%2F07%2F24%2FDeepLearningBookNotes%2F</url>
    <content type="text"><![CDATA[Deep Learning Book Notes深度前馈网络deep feedforward network基于梯度的学习——代价函数： 使用最大似然学习条件分布。大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价。 均方误差和平均绝对误差在使用基于梯度的优化方法时往往成效不佳，一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度，这就是为什么交叉熵代价函数比均方误差或者平均绝对误差更受欢迎的原因之一。 基于梯度的学习——输出单元： 代价函数的选择与输出单元的选择密切相关。任何可用作输出的神经网络单元，也可以被用作隐藏单元。 用于高斯输出分布的线性单元：一种基于仿射变换的输出单元，仿射变换不具有非线性，所以这些单元往往直接被称为线性单元。 用于Bernoulli输出分布（伯努利分布）的sigmoid单元：许多任务需要预测而执行变量的值。具有两个类的分类问题可以归结为这种形式。 用于Multinoulli输出分布（多项分布）的softmax单元：任何时候当我们想要表示一个具有n个可能取值的离散型随机变量的分布时，我们都可以使用softmax函数。它可以看作是sigmoid函数的扩展，其中sigmoid函数用来表示二值型变量的分布。 隐藏单元： 整流线性单元及其扩展：整流线性单元易于优化，它与线性单元非常类似。线性单元和整流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为零。 logistic sigmoid与双曲正切函数： 其他隐藏单元：softmax单元，径向基函数（rational basis function，RBF），softplus函数，硬双曲正切函数（hard tanh) 深度学习中的正则化和优化深度学习中的正则化：对学习算法进行修改，旨在减少泛化误差而不是训练误差。模型族训练有三个情形： 不包括真实的数据生成过程，对应欠拟合和含有偏差的情况； 匹配真实数据生成过程； 除了包括真实的数据生成过程，还包括许多其他可能的生成过程——方差（而不是偏差）主导的过拟合。 正则化的目标是使模型从第三种情况转化为第二种情况。 深度学习中的优化：用于深度模型训练的优化算法与传统的优化算法在几个方面有所不同。机器学习通常是间接作用的。在大多数机器学习问题中，我们关注某些性能度量P，其定义于测试集上并且可能是不可解的。因此，我们只是间接地优化P。我们希望通过降低代价函数J(θ)来提高P，这一点与纯优化不同，纯优化最小化目标J本身。训练深度模型的优化算法通常也会包括一些针对机器学习目标函数的特定结构进行优化。 卷积神经网络convolutional neural network卷积神经网络，也叫做卷积网络，指那些至少在网络的一层中使用卷积运算（卷积运算是一种特殊的线性运算）来替代一般矩阵乘法运算的神经网络。这种网络是一种专门用来处理具有类似网格结构的数据的神经网络，比如时间序列数据和图像数据。 卷积运算： s(t) = ∫x(a)w(t - a)da 上面这种运算称为卷积（convolution）,卷积运算通常用星号*表示。 s(t) = (x * w)(t) 在卷积运算的术语中，卷积的第一个参数（上式中的x）通常叫做输入（input)，第二个参数（上式中的函数w）叫做核函数（kernel），输出有时被称为特征映射（feature map)。 动机：卷积运算通过三个重要思想来帮助改进机器学习系统：稀疏交互（sparse interactions)、参数共享（parameter sharing）、等变表示（equivariant representations)。 池化：卷积网络中一个典型层包含三级。第一级中，这一层并行地计算多个卷积产生一组线性激活响应。第二级中，每一个线性激活响应将会通过一个非线性的激活函数，例如整流线性激活函数。这一级有时也被称为探测级。第三级中，我i们使用池化函数来进一步调整这一层的输出。 池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。 循环神经网络recurrent neural network循环神经网络rnn：这是一类用于处理序列数据的神经网络。 循环神经网络中的一些重要的设计模式： 每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络。 每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的循环网络。 隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的循环网络。 长短期记忆LSTM：引入自循环的巧妙构思，以产生梯度长时间持续流动的路径。]]></content>
      <categories>
        <category>Book Notes</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
</search>
