<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[神经网络结构搜索综述笔记]]></title>
    <url>%2F2019%2F08%2F14%2FNASSurveyNotes%2F</url>
    <content type="text"><![CDATA[NAS_Survey_Notes_Ⅰ Elsken, T., Metzen, J. H., &amp; Hutter, F. (2019). Neural Architecture Search. 20, 63–77. https://doi.org/10.1007/978-3-030-05318-5_3 First Section: Introduction​ NAS (Neural Architecture Search) methods can be categorized to three dimensions: search space, search strategy, and performance estimation strategy. A search strategy selects an architecture A from a predefined search space の，The architecture is passed to a performance estimation strategy, which returns the estimated performance of A to the search strategy. Search Space: The search space defines which architectures can be represented in principle. Search Strategy: The search strategy details how to explore the search space (which is often exponentially large or even unbounded) Performance Estimation Strategy: Performance Estimation refers to the process of estimating this performance: the simplest option is to perform a standard training and validation of the architecture on data, but this is unfortunately computationally expensive and limits the number of architectures that can be explored. Much recent research therefore focuses on developing methods that reduce the cost of these performance estimations. NAS(Neural Architecture Search)神经网络结构搜索方法可以分为三个维度：搜索空间，搜索策略和性能评估策略 搜索策略通过搜索预先定义好的搜索空间，获得候选结构，然后候选结构经过性能评估策略的评估，返回其对应的评估性能，之后反复迭代上述过程，直到选出符合要求性能的网络结构。 搜索空间定义了理论上能够表示的神经网络结构。 搜索策略是指如何探测搜索空间（搜索空间比较大，甚至没有边界） 性能评估策略，则是评估候选网络结构的性能，最简单的方式就是训练和验证这个网络结构，但这样会耗费大量的计算，而且比较耗时，所以需要探索新的方法来减少性能评估的时间和计算开销。 Second Section: Search SpaceThe space of chain-structured neural networks is a relatively simple search space. It is parameterized by (Ⅰ)the (maximum) number of layers n (possibly unbounded); (Ⅱ)the type of operation every layer executes; (Ⅲ)hyperparameters associated with the operation. The space of multi-branch architectures is complex search space. As for this multi-branch architectures , we can search for such motifs, dubbed cells or blocks, respectively, rather than for whole architectures. Zoph et al. (2018) optimize two different kind of cells: a normal cell that preserves the dimensionality of the input and a reduction cell which reduces the spatial dimension. The final architecture is then built by stacking these cells in a predefined manner. This cell-based search space has three major advantages compared with the whole search space: The size of the search space is drastically reduced since cells usually consist of significantly less layers than whole architectures. Architectures built from cells can more easily be transferred or adapted to other data sets by simply varying the number of cells and filters used within a model. Creating architectures by repeating building blocks has proven a useful design principle in general. However, a new design-choice arises when using a cell-based search space, namely how to choose the macro-architecture: how many cells shall be used and how should they be connected to build the actual model?And one direction of optimizing macro-architectures is the hierarchical search space. 链结构神经网络的空间是一个相对简单的搜索空间。它的参数由以下三部分组成：（Ⅰ）（最大）层数n（可能无界）; （二）每层执行的操作类型; （Ⅲ）与操作相关的超参数。 多分支架构的空间是复杂的搜索空间。对于这种多分支架构，我们可以分别搜索单元格或块，而不是整个架构。 Zoph等人。 （2018）优化两种不同类型的单元：保持输入维度的正常单元和减小空间维度的还原单元。然后通过以预定义的方式堆叠这些单元来构建最终的体系结构。与整个搜索空间相比，这种基于单元的搜索空间具有三大优势： 1.搜索空间的大小大大减少，因为单元的层数往往比整个体系结构层数少得多。2.通过简单地改变模型中使用的单元和过滤器的数量，可以更容易地将从单元构建的架构转移或适应其他数据集。3.通过重复构建块来创建体系结构已经被证明是一种有用的设计原则。 然而，当使用基于单元的搜索空间时，出现了一种新的设计选择，即如何选择宏架构：应该使用多少个单元以及如何连接它们来构建实际模型？优化宏架构的一个方向是使用分层搜索空间。 Third Section: Search StrategyMany different search strategies can be used to explore the space of neural architectures, including random search, Bayesian optimization, evolutionary methods, reinforcement learning (RL), and gradient-based methods. Real et al. (2019) conduct a case study comparing RL, evolution, and random search (RS), concluding that RL and evolution perform equally well in terms of final test accuracy, with evolution having better anytime performance and finding smaller models. Both approaches consistently perform better than RS in their experiments, but with a rather small margin: RS achieved test errors of approximately 4% on CIFAR-10, while RL and evolution reached approximately 3.5%. 许多不同的搜索策略可用于探索神经架构的空间，包括随机搜索，贝叶斯优化，进化方法，强化学习（RL）和基于梯度的方法。 Real等人（2019）比较RL，进化算法和随机搜索（RS）这三个算法，得出结论：RL和进化算法在最终测试准确性方面表现同样良好，并且进化算法具有更好的性能，而且找到更小的模型。 两种方法在实验中始终表现优于RS。 Fourth Section: Performance Estimation Strategy Speed-up method How are speed-ups achieved? Lower fidelity estimates低保真估计 Training time reduced by training for fewer epochs, on subset of data, downscaled models, downscaled data.通过训练更少的阶段，数据子集，缩减模型，缩减的数据来减少训练时间。 Learning Curve Extrapolation学习曲线外推 Training time reduced as performance can be extrapolated after just a few epochs of training在几个训练阶段完成之后推断根据学习曲线推断模型性能进而减少训练时间 Weight Inheritance / Network Morphisms权重继承或网络态射 Instead of training models from scratch, they are warm-started by inheriting weights并不是从头开始训练模型，而是继承了权重，可以减少训练次数 One-shot Models/Weight Sharingone-shot模型或权重共享 Only the one-shot model needs to be trained; its weights are then shared across different architectures that are just subgraphs of the one-shot model.只需要训练一个one-shot模型，它的权重被不同的结构所使用，这些不同的结构可以看作是one-shot模型的子图 Appendix Ⅰ : This Survey Mind map]]></content>
      <categories>
        <category>Paper Notes</category>
      </categories>
      <tags>
        <tag>AutoML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化机器学习综述笔记]]></title>
    <url>%2F2019%2F08%2F06%2FAutoMLSurveyNotes%2F</url>
    <content type="text"><![CDATA[Auto Machine Learning Survey Notes(Ⅰ) Paper Name: Yao, Q., Wang, M., Chen, Y., Dai, W., Yi-Qi, H., Yu-Feng, L., … Yang, Y. (2018). Taking Human out of Learning Applications: A Survey on Automated Machine Learning. 1–26. Retrieved from http://arxiv.org/abs/1810.13306 First Section In first section,this paper first explains why we need to investigate AutoML. Its reason is following. Machine Learning has been popular recently , but every aspect of machine learning applications, such as feature engineering, model selection, and algorithm selection, needs to be carefully configured, which costs the efforts of many human experts. So we need to research AutoML to take human out of Learning Application and give experts more time to analyze data and problem,and finally promote the development of Machine Learning. This paper also gives some examples of automated machine learning in industry and academic, like Auto-sklearn, Google’s cloud autoML , and Feature Labs, which shows that AutoML has already been successfully applied in many important problems. 在第一部分中，本文首先解释了为什么我们需要研究AutoML。 因为机器学习近些年很流行，但机器学习应用的各个方面，如特征工程，模型选择和算法选择，都需要仔细配置，这需要许多专业人士的努力。所以我们需要研究AutoML以使人类能够从模型训练中解放出来，能够集中精力分析数据和问题本身，最终促进机器学习的发展。 本文还提供了一些工业和学术界自动化机器学习的例子，如Auto-sklearn，Google的 Cloud AutoML，还有Feature Labs，它们表明了AutoML已成功应用于许多重要问题。 Second SectionIn second section, this paper firstly defines AutoML and its core goal. AutoML attempts to construct machine learning programs(specified by Experience, Task and Performance ),without human assitance and within limited computational budgets. And its three core goals are good performance , no assistance from humans and high computational efficiency. Next, this paper propose a basic framework for AutoML approaches. In this framework, an AutoML controller, which has two key ingredients,the optimizer and the evaluator, takes the place of human to find proper configurations for the learning tools. The duty of the evaluator is to measure the performance of the learning tools with configurations provided by the optimizer , while the optimizer’s duty is to update or generate configurations for learning tools. Finally, this paper shows AutoML approaches taxonomies by problem setup and techniques. 在第二部分中，本文首先定义了AutoML及其核心目标。 AutoML尝试构建机器学习程序（由经验，任务和性能指定），无需人工协助并且在有限的计算预算内。 它的三个核心目标是良好的性能，没有人类的帮助和高计算效率。 接下来，本文提出了AutoML方法的基本框架。 在这个框架中，AutoML控制器取代了人类的工作，为学习方法找到合适的配置方式，这个控制器有两个关键组成部分，即优化器和评估器。 在本节的最后，本文将AutoML的方法分为问题设置和技术处理两类。 Third SectionIn third section, this paper gives details on problem setup and introduces some existing AutoML approaches on learning process. AutoML approaches do not necessarily cover the full machine learning pipeline, they can also focus on some parts of the learning process. As for some parts of the learning process, AutoML approaches includes feature engineering , model selection, and optimization algorithm selection. Feature engineering is to automatically construct features from the data so that subsequent learning tools can have good performance. This goal can be divided into two sub-problems. creating features from the data and enhance features’ discriminative ability. However, there are no common or principled methods to create features from data. So , now AutoML focus on feature enhancing methods and there are some common methods to enhance features, dimension reduction,feature generation and feature encoding. Models selection contains two components, picking up some classifiers and setting their corresponding hyper-parameters. The task of model selection is to automatically select classifiers and set their hyper-parameters so that good learning performance can be contained. The goal of optimization algorithm selection is to automatically find an optimization algorithm so that efficiency and performance can be balanced. What’s more, in this section, this paper give two classes of full-scope AutoML approaches. The first one is general case, which is a combination of feature engineering, model selection and algorithm selection. The second one is Network Architecture Search (NAS), which targets at searching good deep network architectures that suit the learning problem. 在第三部分中，本文详细介绍了问题的设置，并介绍了一些现有的AutoML的方法。AutoML可以不必覆盖机器学习的全范围，仅专注于学习过程中的一部分。 针对机器学习的某些部分，AutoML的方法可分为特征工程，模型选择和优化算法选择。特征工程是从数据中自动构造特征，以便后续学习工具可以具有良好的性能。这个目标可以分为两个子问题，一个是从数据创建功能，另一个是增强功能的辨别能力。但是，没有通用或原则方法从数据创建功能。因此，现在AutoML专注于特征增强方法，并且有一些常用方法可以增强特征，例如降维，特征生成和特征编码。模型选择包含两个组成部分，分别是选取分类器和设置其相应的超参数。模型选择的任务是自动选择分类器并设置其超参数，以便可以包含良好的学习性能。优化算法选择的目标是自动找到优化算法，以便平衡效率和性能。 此外，在本节中，本文提供了两类全范围AutoML方法。第一个是一般情况，它是特征工程，模型选择和算法选择的组合。第二个是网络架构搜索（NAS），其目标是搜索适合学习问题的良好深度网络架构。 Fourth SectionIn fourth section, this paper introduces some basic techniques for optimizer. It has three parts including simple search approaches, optimization from samples and gradient descent. Simple search is a naive search approach, and grid search and random search are two common approaches. Optimization from samples is a kind of smarter search approach, and this paper divide existing approaches into three categories, heuristic search, model-based derivative-free optimization, and reinforcement learning. Some popular heuristic search methods are Particle swarm optimization(PSO), Evolutionary Algorithms. The popular methods of model-based derivative-free optimization are Bayesian optimization, classification-based optimization (CBO) and simultaneous optimistic optimization (SOO) . Reinforcement learning (RL) is a very general and strong optimization framework, which can solve problems with delayed feedbacks. Greedy search is a natural strategy to solve multi-step decision-making problem. 在第四部分中，本文介绍了优化器的一些基本技术。 它有三个部分，包括简单搜索方法，样本优化和梯度下降。 简单搜索是一种朴素的搜索方法，其中两种常见的方法分别是网格搜索和随机搜索。样本优化是一种更智能的搜索方法，本文将现有的相关方法分为三类：启发式搜索，基于模型的无导数优化和强化学习。 一些流行的启发式搜索方法是粒子群优化（PSO），进化算法。 基于模型的无导数优化的流行方法是贝叶斯优化，基于分类的优化（CBO）和同时优化优化（SOO）。 强化学习（RL）是一个非常通用且强大的优化框架，可以解决延迟反馈的问题。此外，贪心搜索是解决多步决策问题的常用策略。 Fifth SectionIn fifth section, this paper introduce some basic techniques for evaluator. And the existing methods are direct evaluation, sub-sampling, early stop, parameter reusing and surrogate evaluator. Direct evaluation is often accurate but expensive, and some other methods have been proposed for acceleration by trading evaluation accuracy for efficiency. 在第五部分，本文介绍了评估器的一些基本技术。 现有的方法有直接评估，子抽样，早期停止，参数重用和代理评估。 直接评估通常是准确的但效率不高，而其他的方法是来通过降低评估准确性来提高效率。 Sixth SectionIn sixth section, this paper introduce some experienced techniques , there are two main topics, meta-learning and transfer learning. Meta-learning helps AutoML, on the one hand, by characterizing learning problems and tools.,on the other hand, the meta-learner encodes past experience and acts as a guidance to solve future problems. Existing meta-learning techniques by categorizing them into three general classes based on their applications in AutoML are following: meta-learning for configuration evaluation (for the evaluator). Meta-learners can be trained as surrogate evaluators to predict performances, applicabilities, or ranking of configurations. Representative applications of meta-learning in configuration evaluation are Model evaluation and General configuration evaluation. meta- learning for configuration generation (for the optimizer). The approaches have promising configuration generation, warming-starting configuration generation , and search space refining. meta-learning for dynamic configuration adaptation. Meta-learning can help to automate this procedure by detecting concept drift and dynamically adapting learningdrift. Transfer learning tries to improve the learning on target domain and learning task, by using the knowledge from the source domain and learning task. Transfer learning has been exploited to reuse trained surrogate models or promising search strategies from past AutoML search (source) and improve the efficiency in current AutoML task (target). By transferring knowledge from previous configuration evaluations, we can avoid training model from scratch for the upcoming evaluations and significantly improve the efficiency. 在第六部分，本文介绍了一些比较先进的技术，主要有两个主题，元学习和迁移学习。 元学习辅助AutoML，一方面通过对学习问题和工具的表征。另一方面，通过编码以往的经验来作为对解决未来问题的指导。 基于AutoML中的应用程序，将现有的元学习技术分为三个通用类： 1.用于配置评估的元学习（用于评估器）。元学习器可以作为代理评估器进行训练，以预测性能，适用性或配置排名。元学习在配置评估中的代表性应用有模型评估和一般配置评估这两种。2.用于配置生成的元学习（用于优化器）。相关方法有：良好配置生成，预热配置生成和搜索空间精炼。3.动态配置适应的元学习。元学习可以通过检测概念转换和动态调整学习转换来帮助AutoML。 迁移学习通过使用来自源域和学习任务的知识，尝试改进对目标域和学习任务的学习。 迁移学习能重用过去AutoML任务（源）经过训练的代理模型或优良的搜索策略，并提高当前AutoML任务（目标）的效率。通过从以前的配置评估中迁移知识，可以避免从头训练模型，显著提高效率。 Seventh SectionIn seventh section, this paper introduce three AutoML examples, Auto-sklearn, NASNet and ExploreKit. In Auto-sklearn, model selection is formulated as a CASH problem, which aims to minimize the validation loss with respect to the model as well as its hyper-parameters and parameters. RL is employed in NAS to search for a optimal sequence of design decisions. Besides, the direct evaluation is used in these works as the evaluator. As RL is slow to converge, to make the search faster, transfer learning, which is firstly used to cut the search space into several blocks. ExploreKit conducts more expensive and accurate evaluations on the candidate features. Error reduction on the validation set is used as the metric for feature importance. Candidate features are evaluated successively according to their ranking, and selected if their usefulness surpass a threshold. This procedure terminates if enough improvement is achieved. The selected features will be used to generate new candidates in the following iterations. 在第七部分中，本文介绍了三个AutoML应用示例，Auto-sklearn，NASNet和ExploreKit。 在Auto-sklearn中，模型选择被公式化为CASH问题，其目的是最小化模型的验证损失函数及其超参数和参数。 NAS使用RL来搜索最佳的设计决策序列，使用直接评估作为整个工作的评估器。但RL收敛缓慢，为了使搜索更快，NAS使用了转移学习，在搜索之前将搜索空间切割成几个块，以加快收敛速度。 ExploreKit对候选功能进行更准确但更低效的评估。将验证集上的错误减少情况用作特征有效性的度量标准，按照相应排名对候选特征进行评估，并选择有效性超过阈值的特征，所选的特征将在以下的迭代中生成新候选。如果实现了足够的效果，则迭代过程终止。 Eighth SectionIn eighth section, this paper reviews the history of AutoML, summarizes how its current status in the academy and industry, and discuss its future work. AutoML only becomes practical and a big focus recently, due to the big data, the increasing computation of modern computers, and of course, the great demand of machine learning application. AutoML is a very complex problem and also an extremely active research area, and there are many new opportunities and problems in AutoML. And there are also many workshops and competitions. Higher efficiency can be achieved by either proposing algorithms for the optimizer, which visit less configurations before reaching a good performance, or designing better methods for the evaluator, which can offer more accurate evaluations but in less time. 在第八部分，本文回顾了AutoML的历史，总结了其在学术界和行业中的现状，并讨论了其未来的发展方向。 由于大数据，现代计算机的计算量不断增加，当然还有机器学习应用的巨大需求，AutoML最近才成为重点。 AutoML是一个非常复杂的问题，也是一个非常活跃的研究领域，AutoML中存在许多新的机会和问题，还有许多研讨会和比赛。 为优化器提出算法可以实现更高的效率，这样使得优化器在达到良好性能之前访问较少的配置；或者为评估器设计更好的方法，这可以在更短的时间内提供更准确的评估。 Appendix Ⅰ : This Survey Mindmap Auto Machine Learning Survey Notes(Ⅱ) Elshawi, R., Maher, M., &amp; Sakr, S. (2019). Automated Machine Learning: State-of-The-Art and Open Challenges. Retrieved from http://arxiv.org/abs/1906.02287 First SectionIn first section, this paper briefly introduces the development of AutoML and explain what is the CASH (Combined Algorithm Selection and Hyper-parameter tuning) problem. 在第一部分中，本文简要介绍了AutoML的发展，并解释了什么是CASH问题。 Second SectionIn Second section, this paper introduces the various techniques that have been introduced to tackle the challenge of warm starting(meta-learning) for AutoML search problem in the context of machine learning and deep learning domains.. These techniques can generally be categorized into three broad groups: learning based on task properties, learning from previous model evaluations and learning from already pretrained models. 在第二部分中，本文介绍了在机器学习和深度学习领域中针对AutoML搜索问题的热启动（元学习）挑战所引入的各种技术。 这些技术通常可以分为三大类：从任务属性中学习，从先前模型评估中学习以及从已经预训练的模型中学习。 Third SectionIn third section, this paper introduces the various approaches that have been introduced for tackling the challenge of neural architecture search(NAS) in the context of deep learning. Broadly, NAS techniques falls into five main categories including random search, reinforcement learning, gradient- based methods, evolutionary methods, and Bayesian optimization. 在第三部分中，本文介绍了在深度学习环境中应对神经结构搜索（NAS）挑战的各种方法。 从广义上讲，NAS技术分为五大类，包括随机搜索，强化学习，基于梯度的方法，进化方法和贝叶斯优化。 Fourth SectionIn fourth section, this paper introduces some different approaches for automated hyper-parameter optimization. In principle, the automated hyper-parameter tuning techniques can be classified into two main categories: black-box optimization techniques and multi-fidelity optimization techniques. 在第四部分中，本文介绍了一些不同的自动超参数优化的方法。 原则上，自动超参数调整技术可以分为两大类：黑盒优化技术和多保真优化技术。 Fifth SectionIn fifth section, this paper covers the various tools and frameworks that have been implemented to tackle the CASH problem. In general, these tools and frameworks can be classified into three main categories: centralized, distributed, and cloud-based. And Neural Network Automation Frameworks is also a class recently. 在第五部分中，本文介绍了为解决CASH问题而实施的各种工具和框架。 这些工具和框架可以分为三大类：集中式框架，分布式框架和基于云平台的框架。此外，神经网络自动化框架也逐渐发展起来。 Sixth SectionIn sixth section, this paper introduces some state-of-the-art research efforts on tackling the automation aspects for the other building blocks (Pre-modeling and Post-Modeling) of the complex machine learning pipeline. 在第六部分中，本文介绍了一些关于自动化复杂机器学习问题中的其他构建模块（比如预建模和后建模）的前沿研究工作，。 Seventh SectionIn seventh section, this paper introduces some research directions and challenges that need to be addressed in order to achieve the vision and goals of the AutoML process. It includes scalability, optimization techniques, time budget, composability, user friendliness, continuous delivery pipeline, data validation, data preparation, and model deployment and life cycle. 在第七部分中，本文介绍了为了实现AutoML过程的这个目标，需要进一步研究的的一些方向和挑战。它包括可扩展性，优化技术，时间预算，可组合性，用户友好性，持续交付管道，数据验证，数据准备，模型部署和生命周期。 Appendix Ⅰ : This Survey Mind map Auto Machine Learning Survey Notes(Ⅲ) Zöller, M.-A., &amp; Huber, M. F. (2019). Survey on Automated Machine Learning. Retrieved from http://arxiv.org/abs/1904.12054 First SectionIn first section, this paper introduces the history of AutoML, and shows AutoML is no new trend. It also gives this paper’s contributions: introduce a mathematical formulation covering the complete procedure of automatic ML pipeline creation, cover AutoML techniques for each step of building an ML pipeline, and evaluate all presented algorithms. Finally, it shows this paper’s structure. 在第一部分中，本文介绍了自动化机器学习的发展历史，并指出它并不是一个新的趋势。本文还给出了这篇论文的贡献：介绍了一个覆盖整个自动化机器学习过程的数学公式，介绍了构建机器学习流水线的每一步的automl技术，并对所提出的所有算法进行了评估。最后给出了这篇论文的脉络结构。 Second SectionIn second section, this paper gives a mathematical sound formulation of the automatic construction of ML pipelines is given. And it shows most current state-of-the-art algorithms solve the pipeline creation problem in two distinct stages, pipeline structure search, and Algorithm selection and hyperparameters optimization. 第二部分给出了ML流水线自动构造的数学合理公式。并说明了目前最先进的算法如何解决了流水线创建问题，分为两个子问题，分别是流水线结构搜索和算法选择及超参数优化。 Third SectionIn third section, this paper introduces some approaches about pipeline structure creation. a basic ML pipeline layout: At first, the input data is cleaned in multiple distinct steps, like imputation of missing data and one-hot encoding of categorical input. Next, relevant features are selected and new features created in a feature engineering stage. This stage highly depends on the underlying domain. Finally, a single model is trained on the previously selected features. a fixed pipeline shape： Fixed ML pipeline used by most AutoML frameworks. Minor differences exist regarding the implemented data cleaning steps. Regarding data cleaning, the pipeline shape differs. Yet, often the two steps imputation and scaling are implemented. Even though this approach greatly reduces the complexity of the pipeline creation problem, it leads to inferior pipeline performances for complex data sets. Fixed shaped ML pipelines lack this flexibility to adapt to a specific task. some variable shapes: genetic programming, Genetic programming is an iterative, domain-agnostic optimization method derived from biological evolution. hierarchical task networks(HTNs)，HTNs are a method from automated planning that recursively partition a complex problem into easier subproblems. self-play, Self-play (Lake et al., 2017) is a reinforcement learning strategy, the algorithm creates new training examples by playing against itself. A common drawback of self-play approaches is the low convergence speed making this approach rather unsuited for AutoML. 第三部分介绍了一些关于机器学习流水线创建的方法。 首先介绍了一个基本的机器学习流水线布局，在这个布局里，输入数据先被清洗，然后从中提取出特征，最后，根据提取出的特征训练模型。 之后，介绍了固定的流水线布局，这个布局被大部分自动化机器学习框架采用。这个布局与基本的机器学习流水线布局相比，只有在数据清洗的步骤有所差异。在该布局中，数据清洗是由两个步骤完成的，插补和缩放。尽管这种布局极大地减少了流水线创建的复杂度，但它也使得流水线在处理复杂的数据集时性能不高。而且，这种布局还缺乏适应特定任务的灵活性。 最后，介绍了一些流水线布局的变体。第一个是基于遗传编码的变体，这种方法是一中从生物进化借鉴而来的迭代优化方法；第二个是基于层次任务网络的方法，这种方法是一种自动地将复杂问题递归地划分为简单问题的方法。第三个是self-play方法，这个是一种强化学习的策略，这个方法通过与自身对抗创建新的训练示例，但是这个方法的一个常见缺点就是收敛速度低，因此它不是很适合autoML。 Fourth SectionIn fourth section, this paper shows some approaches to solve CASH problem (the combined algorithm selection and hyperparameter optimization, both steps are executed simultaneously) . Grid Search, The first approach proposed to systematically explore the configuration space was grid search. grid search creates a grid of configurations and evaluates all of them. Therefore, each continuous hyperparameter is discretized into k (logarithmic) equidistant values. This basic algorithm does not scale well for large configuration spaces, as the number of function evaluations grows exponentially with the number of hyperparameters. Random Search, A candidate configuration is generated by randomly choosing a value for each hyperparameter independently of all others. Random search is straightforward to implement and parallelize and well suited for gradient-free functions with many local minima . Sequential Model-Based Optimization: Gaussian Process, Even though a Gaussian process is a non-parametric model, it still requires hyperparameters itself, namely the selection of m and k. A common drawback of Gaussian processes is the runtime complexity of O(n3) due to the inversion of K. Random Forests, Random forest regression is an ensemble method consisting of multiple regression trees Tree-structured parzen estimator, TPE natively handles hierarchical search spaces by modeling each hyperparameter individually by two one-dimensional distributions. Evolutionary Algorithm: Genetic Programming, genetic programming should only be used for CASH in combination with ML pipeline structure search. Because some concepts cannot be easily applied to algorithm selection: a crossover between a SVM and a decision tree cannot be modeled reasonably. Particle Swarm Optimization, PSO tends to converge faster to a local minimum in comparison to genetic programming . Multi-Armed Bandit Learning, Multi-armed bandit learning is limited to a finite number of bandits. Gradient Descent, A very powerful optimization method is gradient descent, an iterative minimization algorithm. 在第四部分，论文主要介绍了一些解决CASH问题的方法。 算法选择和超参数优化两个步骤同步进行，这个简称CASH问题。 网格搜索：这是第一个系统搜索配置空间的方法。网格搜索为配置创建了一个网格，并且对它们进行了评估。同时每一个连续的超参数都被等价地离散化为k个值。这个基础的算法不能很好地解决较大配置空间的问题，因为评估函数的数量将会随着超参数的数量指数级增长。 随机搜索：通过随机地为每一个独立的超参数选择一个值，便可以产生一个候选的配置，随机搜索很容易实现，也很容易并行化，非常适合具有许多局部最小值的无梯度函数。 基于序列模型的优化： 高斯过程：尽管一个高斯过程是一个无参数的模型，但它本身依旧需要超参数，比如m和k的选择。高斯过程一个普遍的缺点就是由于k的反转而导致的高时间复杂度O(n3)。 随机森林：随机森林回归是有多个回归树组成一个集成方法 树形结构的parzen估计：TPE通过两个一维分布分别对每个超参数进行建模，进而在本地处理分层搜索空间 进化算法： 遗传编码：遗传编码只能用于CASH和机器学习流水线结构查找相结合，因为某些概念不能轻易应用于算法选择：SVM和决策树之间的交叉无法合理地建模。 粒子群优化算法：和遗传编码相比，PSO更快地收敛到局部最小值。 多臂赌博机学习：仅限于有限数量的赌博机。 梯度下降法：基于迭代的最小化算法。 Fifth SectionData cleaning is an important aspect of building an ML pipeline. The purpose of data cleaning is improving the quality of a data set by removing data errors. Common error classes are missing values in the input data, invalid values or broken links between entries of multiple data sets. 数据清理是构建ML流水线的一个重要方面。 数据清洗的目的通过消除数据错误来提高数据集的质量。 常见错误类别有输入数据中缺少的值，无效值或多个数据集的条目之间的连接缺失。 Sixth SectionThe task of feature engineering is highly domain specific and very difficult to generalize. Even for a data scientist assessing the impact of a feature is difficult, as domain knowledge is necessary. Consequently, feature engineering is a mainly manual and time-consuming task driven by trial and error. Feature selection is the easier part of feature engineering as the search space is very limited: each feature can either be included or excluded. Consequently, many different algorithms for feature selection exist. Basically all automatic feature generation approaches follow the iterative scheme. Based on an initial data set, a set of candidate features is generated and ranked. High ranking features are evaluated and potentially added to the data set. These three steps are repeated several times. 特征工程的任务是和领域高度相关的，很难统一概括。 因此即使是数据科学家也很难对特征的优劣进行评估。 因此，特征工程是一个主要由人类参与且耗时巨大的试错过程。 特征选择是特征工程中比较容易的部分，因为搜索空间非常有限：可以包含或排除某个特征。 现在存在许多用于特征选择的不同算法。 而至于特征生成方面，基本上所有自动特征生成方法都遵循迭代方案。 基于初始数据集，生成并排列一组候选特征。 评估并对这些其中排序靠前的特征，并有可能添加到数据集中。 这三个步骤重复几次，直到生成符合要求的特征。 Seventh SectionIn seventh section, this paper introduces different performance improvements. Multi-Fidelity Approximations: Depending on the used data set, fitting a single model can take several hours, in extreme cases even up to several days. Consequently, optimization progress is very slow. A common approach to circumvent this limitation is the usage of multi-fidelity approximations. By testing a configuration on this training subset, bad performing configurations can be discarded very fast and only well performing configurations have to be tested on the complete training set. Early Stopping: A quite simple approximation is aborting the fitting after the first fold if the performance is significantly worse than the current incumbent. Scalability: A common strategy for solving a computational heavy problem is parallelization on multiple cores or within a cluster. As AutoML normally has to fit many ML models, distributing different fitting instances in a cluster is an obvious idea. Ensemble Learning: Ensemble methods combine multiple ML models to create predictions. Depending on the diversity of the combined models, the overall accuracy of the predictions can be significantly increased. The cost of evaluating multiple ML models is often neglectable considering the performance improvements. Meta-Learning: Meta-learning can be used in multiple stages of automatically building an ML pipeline to increase the efficiency. Search Space Refinements, Filtering of Candidate Configurations, Warm-Starting, Pipeline Structure. 在第七部分，论文介绍了几种不同的优化方法，多保真估计，早停，扩展，集成学习和元学习。 多保真估计：通过测试该训练子集上的配置，可以非常快速地丢弃性能差的配置，并且只需要在完整的训练集上测试性能良好的配置。 早停： 一个非常简单的近似是在第一次折叠后如果性能明显比当前的差，那么中止拟合。 扩展：由于AutoML通常必须适合许多ML模型，因此在一个群集中分配不同的拟合实例是一个直接的想法。 集成学习：集成学习结合多个ML模型来进行预测。 元学习：元学习可以在自动构建ML流水线的多个阶段中使用，以提高效率。 Eighth SectionIn this section, papers introduces some existing frameworks: 在第八部分，论文介绍了一些现有的框架。 Appendix Ⅰ：This Survey Mind map]]></content>
      <categories>
        <category>Paper Notes</category>
      </categories>
      <tags>
        <tag>AutoML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习读书笔记（Ⅰ）]]></title>
    <url>%2F2019%2F07%2F24%2FMachineLearningBookNotes%2F</url>
    <content type="text"><![CDATA[Notes on Machine Learning重要名词解释Important Expressions训练集train set： 用于模型训练的数据集 验证集validation set：用于进行模型评估和模型选择的数据集 测试集test set：用来评估模型在实际使用中的泛化能力 形象上来说训练集就像是学生的课本，学生 根据课本里的内容来掌握知识，验证集就像是作业，通过作业可以知道 不同学生学习情况、进步的速度快慢，而最终的测试集就像是考试，考的题是平常都没有见过，考察学生举一反三的能力。 错误率error rate:分类错误的样本数占样本总数的比例 精度accuracy：分类正确的样本数占样本总数的比例 线性模型Linear Model线性判别分析Linear Discriminant Analysis,LDA:用于解决二分类问题的经典线性学习方法。主要思想：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离。 多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。 最经典的拆分策略有三种：“一对一”（One vs One, OvO)，“一对其余”（One vs Rest，OvR) 和 “多对多”（Many vs Many，MvM） 类别不平衡问题class-imbalance:指分类任务中不同类别的训练样例数目差别很大的情况。三类处理方案，第一类是欠采样（under sampling)即去除训练集中数目较多类别的样例；第二类是过采样（over sampling)即增加训练集中数目较少类别的样例；第三类是直接基于原始训练集进行训练，但在使用分类器进行预测时修改决策过程，进行“阈值移动”（threshold moving)。 决策树Decision Tree决策树的划分目标：决策树的分支节点所包含的样本尽可能属于同一类别，即结点的“纯度”（purity）越来越高。 神经网络Neural Networks多层前馈神经网络（multi-layer feedforward neural networks)：每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络称之为多层前馈神经网络。 神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”（connection weight）以及每个功能神经元的阈值；换言之。神经网络学到的东西，蕴含在连接权与阈值中。 常见的神经网络： RBF(Radial Basis Function，径向基函数)网络，这是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。 ART（Adaptive Resonance Theory， 自适应谐振理论）网络，它采用竞争型学习（一种常用的无监督学习策略）的策略，由比较层、识别层、识别阈值和重置模块构成。 SOM（Self-Organizing Map，自组织映射）网络，这是一种竞争学习型的无监督神经网络，它能将高位输入数据映射到低维空间（通常是二维）,同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元。 级联相关网络（cascade-correlation) 是结构自适应的神经网络。 Elman网络是递归神经网络。与前馈神经网络不同，递归神经网络（recurrent neural networks)允许网络中出现环形结构，从而可以让一些神经元的输出反馈回来作为输入信号。 Boltzmann机：这是一种“基于能量的模型”（energy-based model)。神经网络中有一类模型是为网络状态定义一个“能量”（energy），能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数。 深度学习deep learning：典型的深度学习模型就是很深层的神经网络。对于神经网络模型，提高容量的一个简单办法就是增加隐层数目，然而多隐层神经网络难以直接使用经典算法（比如标准BP算法）进行训练，因为误差在多隐层内逆传播时，往往会“发散”（diverge）而不能收敛到稳定状态，所以无监督逐层训练（unsupervised layer-wise training)是多隐层网络训练的有效手段，即采用预训练+微调的做法对多隐层网络进行训练，这样可以有效地节省了训练开销。 另一种节省训练开销的策略是”权共享（weight sharing)”，即让一组神经元使用相同的连接权，这个策略在卷积神经网络(Convolutional Neural Network)发挥了重要作用。 贝叶斯分类Bayes Classifier*朴素贝叶斯分类器（naive Bayes classifier) *：朴素贝叶斯分类器采用了属性条件独立假设（attribute conditional independence assumption)，即对已知类别，假设所有属性相互独立，换言之，假设每个属性独立地对分类结果发生影响。之所以使用朴素贝叶斯分类器，是因为贝叶斯分类器难以从有限的训练样本中直接估计所有属性上的联合概率。 EM(Expectation-Maximization)算法：是一种迭代式的方法，用于计算参数隐变量，其基本思想是：若参数Θ已知，则可以根据训练数据推断出最优隐变量Z的值（E步）；反之，若Z的值已知，则可以方便地对参数Θ做最大似然估计（M步）。 集成学习Ensemble Learning*集成学习(ensemble learning) *：通过构建并结合多个学习器来完成学习任务，也被称为多分类器系统（multi-classifier system)。根据个体学习器的生成方式，目前的集成学习方法大致可分为两类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，代表算法是Boosting；另一类是个体学习器之间不存在强依赖关系，可同时生成的并行化方法，代表是Bagging和随机森林（Random Forest)。 Boosting：这是一族可将弱学习器提升为强学习器的算法。这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续收到更多关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最终将这T个基学习器进行加权结合。 Bagging：这是一种并行式集成学习方法，它直接基于自助采样法（Bootstrap sampling)。给定包含m个样本的数据集，先随机取出一个样本放入采样集中，再把样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m次随机采样操作，我们得到m个样本的采样集。其中初始训练集中约有63.2%的样本出现在采样集中。照这样可以采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合，这就是Bagging的基本流程。 随机森林(Random Forest，RF)：RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。具体来说，传统的决策树在选择划分属性时实在当前结点的属性集合（假设有d个属性）中选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最有属性用于划分，这里的参数k控制了随机性的引入程度。 结合策略：平均法，投票法和学习法（通过另一个学习器来结合个体学习器，即通过次级学习器来结合初级学习器）。 聚类Clustering聚类(clustering)：聚类算法是无监督学习（unsupervised learning)，训练样本的标记信息未知，通过聚类，试图将数据集中的样本划分为若干个通常不相交的子集，每个子集称为一个“簇”（cluster)。聚类过程仅能自动形成簇结构，而簇所对应的概念语义需要使用者来进行命名和把握。聚类算法涉及的两个基本问题是性能度量和距离计算。 性能度量(validity index)：性能度量大致有两类： 一类是将聚类结果与某个参考模型（reference model)比较，称为“外部指标”（external index），常用的外部指标有Jaccard系数（Jaccard Coefficient, JC），FM指数（Fowlkes and Mallows Index, FMI)和Rand指数（Rand Index,RI)。这些指数越大说明聚类效果越好。 另一类是直接考察聚类结果而不利用任何参考模型，称为“内部指标”（Internal index)，常用的内部指标有DB指数（Davies-Bouldin Index, DBI）和Dunn指数（Dunn Index,DI)。内部指标中DBI的值越小越好，而DI的值越大越好。 密度聚类（density-based clustering）：通常情形下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果。DBSCAN是一种著名的密度聚类算法。 层次聚类（hierarchical clustering）：这种聚类算法试图在不同层次对数据集进行划分，从而形成树形的聚类结构。AGNES是一种采用自底向上聚合策略的层次聚类算法。 半监督学习Semi-supervised Learning半监督学习（semi-supervised learning)：让学习器不依赖外界交互，自动利用未标记样本来提升学习性能。 半监督支持向量机（semi-supervised support vector machine, S3VM)：这是支持向量机在半监督学习上的推广。 半监督聚类（semi-supervised clustering)：聚类是典型的无监督学习任务，但现实的聚类任务中，我们往往能获取到一些额外的监督信息，这些信息大致有两类，一类是必连（指样本必属于同一个簇）与勿连（指样本必不属于同一个簇）约束，另一类是少量的标记样本。利用这些监督信息，我们可以通过半监督聚类来获得更好的聚类效果。 规则学习Rule Learning规则学习（rule learning)：规则学习是从训练数据中学习出一组能用于对未见示例进行判别的规则。 序贯覆盖（sequential covering)：即逐条归纳，在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程。由于每次只处理一部分数据，因此也被称为“分治”（separate-and-conquer)策略。 一阶规则学习，FOIL算法（First-Order Inductive Learner)：FOIL是著名的一阶规则学习算法，它遵循序贯覆盖框架并且采用自顶向下的规则归纳策略，由于逻辑变量的存在，FOIL在规则生成时需要考虑不同的变量组合。 归纳逻辑程序设计（Inductive Logic Programming，ILP）：归纳逻辑程序设计在一阶规则学习中引入了函数和逻辑表达式嵌套。 强化学习Reinforcement Learning强化学习：强化学习的学习目的就是要找到能使长期累积奖赏最大化的策略。强化学习中没有标记样本，即没有人直接告诉机器在什么状态下应该做什么动作，只有等到最终结果揭晓，才能通过“反思”之前动作是否正确来进行学习，因此，强化学习在某种意义上可看作具有“延迟标记信息”的监督学习问题。 探索与利用(Exploration and Exploitation)：探索（“估计摇臂的优劣”）和利用（“选择当前最优摇臂”）这两者是矛盾的，因为尝试次数有限，加强了一方则会自然削弱另一方，这是强化学习所面临的“探索利用窘境”（Exploration-Exploitation dilemma)。显然，想要强化学习累积奖赏最大，需要在探索和利用之间达到较好的折中。 模仿学习（imitation learning)：在强化学习的经典任务设置中，机器所能获得的反馈信息仅有多步决策后的累计奖赏，但在现实任务中，往往能得到人类专家的决策过程范例，从这样的范例中学习，称为“模仿学习”（imitation learning）。]]></content>
      <categories>
        <category>Book Notes</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习读书笔记（Ⅰ）]]></title>
    <url>%2F2019%2F07%2F24%2FDeepLearningBookNotes%2F</url>
    <content type="text"><![CDATA[Deep Learning Book Notes深度前馈网络deep feedforward network基于梯度的学习——代价函数： 使用最大似然学习条件分布。大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价。 均方误差和平均绝对误差在使用基于梯度的优化方法时往往成效不佳，一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度，这就是为什么交叉熵代价函数比均方误差或者平均绝对误差更受欢迎的原因之一。 基于梯度的学习——输出单元： 代价函数的选择与输出单元的选择密切相关。任何可用作输出的神经网络单元，也可以被用作隐藏单元。 用于高斯输出分布的线性单元：一种基于仿射变换的输出单元，仿射变换不具有非线性，所以这些单元往往直接被称为线性单元。 用于Bernoulli输出分布（伯努利分布）的sigmoid单元：许多任务需要预测而执行变量的值。具有两个类的分类问题可以归结为这种形式。 用于Multinoulli输出分布（多项分布）的softmax单元：任何时候当我们想要表示一个具有n个可能取值的离散型随机变量的分布时，我们都可以使用softmax函数。它可以看作是sigmoid函数的扩展，其中sigmoid函数用来表示二值型变量的分布。 隐藏单元： 整流线性单元及其扩展：整流线性单元易于优化，它与线性单元非常类似。线性单元和整流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为零。 logistic sigmoid与双曲正切函数： 其他隐藏单元：softmax单元，径向基函数（rational basis function，RBF），softplus函数，硬双曲正切函数（hard tanh) 深度学习中的正则化和优化深度学习中的正则化：对学习算法进行修改，旨在减少泛化误差而不是训练误差。模型族训练有三个情形： 不包括真实的数据生成过程，对应欠拟合和含有偏差的情况； 匹配真实数据生成过程； 除了包括真实的数据生成过程，还包括许多其他可能的生成过程——方差（而不是偏差）主导的过拟合。 正则化的目标是使模型从第三种情况转化为第二种情况。 深度学习中的优化：用于深度模型训练的优化算法与传统的优化算法在几个方面有所不同。机器学习通常是间接作用的。在大多数机器学习问题中，我们关注某些性能度量P，其定义于测试集上并且可能是不可解的。因此，我们只是间接地优化P。我们希望通过降低代价函数J(θ)来提高P，这一点与纯优化不同，纯优化最小化目标J本身。训练深度模型的优化算法通常也会包括一些针对机器学习目标函数的特定结构进行优化。 卷积神经网络convolutional neural network卷积神经网络，也叫做卷积网络，指那些至少在网络的一层中使用卷积运算（卷积运算是一种特殊的线性运算）来替代一般矩阵乘法运算的神经网络。这种网络是一种专门用来处理具有类似网格结构的数据的神经网络，比如时间序列数据和图像数据。 卷积运算： s(t) = ∫x(a)w(t - a)da 上面这种运算称为卷积（convolution）,卷积运算通常用星号*表示。 s(t) = (x * w)(t) 在卷积运算的术语中，卷积的第一个参数（上式中的x）通常叫做输入（input)，第二个参数（上式中的函数w）叫做核函数（kernel），输出有时被称为特征映射（feature map)。 动机：卷积运算通过三个重要思想来帮助改进机器学习系统：稀疏交互（sparse interactions)、参数共享（parameter sharing）、等变表示（equivariant representations)。 池化：卷积网络中一个典型层包含三级。第一级中，这一层并行地计算多个卷积产生一组线性激活响应。第二级中，每一个线性激活响应将会通过一个非线性的激活函数，例如整流线性激活函数。这一级有时也被称为探测级。第三级中，我i们使用池化函数来进一步调整这一层的输出。 池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。 循环神经网络recurrent neural network循环神经网络rnn：这是一类用于处理序列数据的神经网络。 循环神经网络中的一些重要的设计模式： 每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络。 每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的循环网络。 隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的循环网络。 长短期记忆LSTM：引入自循环的巧妙构思，以产生梯度长时间持续流动的路径。]]></content>
      <categories>
        <category>Book Notes</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
</search>
